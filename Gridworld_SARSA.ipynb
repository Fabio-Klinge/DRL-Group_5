{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of SARSA solving a gridworld environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as r\n",
    "from operator import add\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gridworld:\n",
    "\n",
    "    def __init__(self, size=8, reward=10):\n",
    "        self.size = size\n",
    "        self.reward = reward\n",
    "\n",
    "        # Create 2d list with filled with zeros\n",
    "        self.grid = [[0] * self.size for i in range(self.size)]\n",
    "\n",
    "        # Current state of agent\n",
    "        self.current_state = None\n",
    "        self.blocked_fields = None\n",
    "        self.goal_idx = None\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "\n",
    "        # Input error correction\n",
    "        if self.size < 5 or isinstance(self.size, int) == False:\n",
    "            print(\"The size entered for the grid is too small or was no integer. Please try an integer bigger than 4.\")\n",
    "\n",
    "        else:\n",
    "            # Create negative fields\n",
    "            for j in range(int(self.size)):\n",
    "                self.grid[r.randint(0, self.size-1)][r.randint(0, self.size-1)] = r.uniform(-1, 0)\n",
    "\n",
    "            # Saves indeces of blocked field\n",
    "            blocked_fields_idx = []\n",
    "            # Create blocked fields\n",
    "            for k in range(int(self.size/1.5)):\n",
    "                blocked_fields = [r.randint(0, self.size-1), r.randint(0, self.size-1)]\n",
    "                blocked_fields_idx.append(blocked_fields)\n",
    "\n",
    "                self.grid[blocked_fields[0]][blocked_fields[1]] = \"X\"\n",
    "\n",
    "            # Save list of blocked fields for step() function\n",
    "            self.blocked_fields = blocked_fields_idx\n",
    "\n",
    "            # initial index of terminal state\n",
    "            goal_idx = [r.randint(0, self.size-1), r.randint(0, self.size-1)]\n",
    "\n",
    "            # Check adjacent fields to index of terminal state and update until no blocked field is adjacent\n",
    "            while list(map(add, goal_idx, [0, -1])) in blocked_fields_idx or list(\n",
    "                    map(add, goal_idx, [0, +1])) in blocked_fields_idx or list(\n",
    "                    map(add, goal_idx, [-1, 0])) in blocked_fields_idx or list(\n",
    "                    map(add, goal_idx, [+1, 0])) in blocked_fields_idx:\n",
    "                goal_idx = [r.randint(0, self.size-1), r.randint(0, self.size-1)]\n",
    "\n",
    "            # Save index of terminal state for step() function\n",
    "            self.goal_idx = goal_idx\n",
    "\n",
    "            # Create terminal state with positive reward\n",
    "            self.grid[goal_idx[0]][goal_idx[1]] = self.reward\n",
    "\n",
    "            starting_point_idx = [r.randint(0, self.size-1), r.randint(0, self.size-1)]\n",
    "\n",
    "            # Update starting point until it is a zero value (Not blocked- or terminal field)\n",
    "            while self.grid[starting_point_idx[0]][starting_point_idx[1]] != 0:\n",
    "                starting_point_idx = [r.randint(0, self.size-1), r.randint(0, self.size-1)]\n",
    "\n",
    "            # Set current state to starting state\n",
    "            self.current_state = starting_point_idx\n",
    "\n",
    "            return self.state_as_int(self.current_state)\n",
    "\n",
    "    def step(self, action: int, new_state: list) -> tuple[int, int, bool]:\n",
    "        '''\n",
    "        Moves agent in grid\n",
    "\n",
    "        args:\n",
    "        action(int): How agent should move (0=left, 1=right, 2=up, 3=down)\n",
    "        '''\n",
    "        self.current_state: list = new_state\n",
    "\n",
    "        # Left\n",
    "        if action == 0:\n",
    "            # Compute result of action\n",
    "            test_state = list(map(add, self.current_state, [0, -1]))\n",
    "\n",
    "            # New list index is out of bounds (left)\n",
    "            if test_state[1] == -1:\n",
    "                #print(\"Wall\")\n",
    "                pass\n",
    "\n",
    "            # New list index is on field marked with \"X\"\n",
    "            elif test_state in self.blocked_fields:\n",
    "                #print(\"field blocked\")\n",
    "                pass\n",
    "\n",
    "            # Action lead to terminal state\n",
    "            elif test_state == self.goal_idx:\n",
    "                #print(\"Terminal state reached\")\n",
    "                self.current_state = test_state\n",
    "                done = True\n",
    "\n",
    "            # Update state (take action)\n",
    "            else:\n",
    "                self.current_state = test_state\n",
    "                self.done = False\n",
    "            \n",
    "            # Return new state, reward & bool wether terminal state is reached\n",
    "            return self.state_as_int(self.current_state), self.grid[self.current_state[0]][\n",
    "                self.current_state[1]], self.done\n",
    "\n",
    "        # Right\n",
    "        if action == 1:\n",
    "            # Compute result of action\n",
    "            test_state = list(map(add, self.current_state, [0, +1]))\n",
    "\n",
    "            # New list index is out of bounds (right)\n",
    "            if test_state[1] == self.size:\n",
    "                #print(\"Wall\")\n",
    "                pass\n",
    "\n",
    "            # New list index is on field marked with \"X\"\n",
    "            elif test_state in self.blocked_fields:\n",
    "                #print(\"field blocked\")\n",
    "                pass\n",
    "\n",
    "            # Action lead to terminal state\n",
    "            elif test_state == self.goal_idx:\n",
    "               #print(\"Terminal state reached\")\n",
    "                self.current_state = test_state\n",
    "                self.done = True\n",
    "\n",
    "            # Update state (take action)\n",
    "            else:\n",
    "                self.current_state = test_state\n",
    "\n",
    "            # Return new state, reward & bool wether terminal state is reached\n",
    "            return self.state_as_int(self.current_state), self.grid[self.current_state[0]][\n",
    "                self.current_state[1]], self.done\n",
    "\n",
    "\n",
    "        # Up\n",
    "        if action == 2:\n",
    "            # Compute result of action\n",
    "            test_state = list(map(add, self.current_state, [-1, 0]))\n",
    "\n",
    "            # New list index is out of bounds (right)\n",
    "            if test_state[0] == -1:\n",
    "                #print(\"Wall\")\n",
    "                pass\n",
    "\n",
    "            # New list index is on field marked with \"X\"\n",
    "            elif test_state in self.blocked_fields:\n",
    "                #print(\"field blocked\")\n",
    "                pass\n",
    "\n",
    "            # Action lead to terminal state\n",
    "            elif test_state == self.goal_idx:\n",
    "                #print(\"Terminal state reached\")\n",
    "                self.current_state = test_state\n",
    "                self.done = True\n",
    "\n",
    "            # Update state (take action)\n",
    "            else:\n",
    "                self.current_state = test_state\n",
    "\n",
    "            # Return new state, reward & bool wether terminal state is reached\n",
    "            return self.state_as_int(self.current_state), self.grid[self.current_state[0]][\n",
    "                self.current_state[1]], self.done\n",
    "                \n",
    "\n",
    "        # down\n",
    "        if action == 3:\n",
    "            # Compute result of action\n",
    "            test_state = list(map(add, self.current_state, [+1, 0]))\n",
    "\n",
    "            # New list index is out of bounds (right)\n",
    "            if test_state[0] == self.size:\n",
    "                #print(\"Wall\")\n",
    "                pass\n",
    "\n",
    "            # New list index is on field marked with \"X\"\n",
    "            elif test_state in self.blocked_fields:\n",
    "                #print(\"field blocked\")\n",
    "                pass\n",
    "\n",
    "            # Action lead to terminal state\n",
    "            elif test_state == self.goal_idx:\n",
    "                #print(\"Terminal state reached\")\n",
    "                self.current_state = test_state\n",
    "                self.done = True\n",
    "\n",
    "            # Update state (take action)\n",
    "            else:\n",
    "                self.current_state = test_state\n",
    "\n",
    "            # Return new state, reward & bool wether terminal state is reached\n",
    "            return self.state_as_int(self.current_state), self.grid[self.current_state[0]][\n",
    "                self.current_state[1]], self.done\n",
    "\n",
    "        #print(self.current_state)\n",
    "\n",
    "    def state_as_int(self, state: list) -> int:\n",
    "        return (state[0] * self.size) + state[1]\n",
    "\n",
    "    def int_as_state(self, index):\n",
    "        return [int(index / self.size), int(index % self.size)]\n",
    "\n",
    "    def visualise(self):\n",
    "        print(self.current_state, self.goal_idx)\n",
    "        # Print in matrix format - Rest of program still uses lists\n",
    "        print(np.matrix(self.grid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARSA implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "episodes = 60000\n",
    "steps = 100\n",
    "alpha = 0.8\n",
    "gamma = 0.9\n",
    "\n",
    "state_space = 6\n",
    "action_space = 4\n",
    "grid = Gridworld(state_space)\n",
    "start_state = grid.reset()\n",
    "\n",
    "q_values = np.zeros(((state_space*state_space), action_space))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [02:39<00:00, 375.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.64318419e-240  1.60076101e+000 -5.17399826e-001 -1.17888402e-008]\n",
      " [-3.41084246e-042 -9.77898022e-002 -5.17399826e-001 -1.48539310e-006]\n",
      " [-1.58227054e-027  1.60256000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [-1.00376131e-001  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]\n",
      " [ 0.00000000e+000  0.00000000e+000  0.00000000e+000  0.00000000e+000]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to learn the Q-value for state, action pair\n",
    "# Represents TD Error for SARSA\n",
    "def update(state, new_state, reward, action, new_action):\n",
    "    prediction = q_values[state, action]\n",
    "    target = reward + gamma * q_values[new_state, new_action]\n",
    "    q_values[state, action] = q_values[state, action] + alpha * (target - prediction)\n",
    "\n",
    "\n",
    "# Starting the SARSA learning\n",
    "for episode in tqdm(range(episodes)):\n",
    "    t = 0\n",
    "    \n",
    "    action = np.argmax(q_values[start_state, :])\n",
    "    state = start_state\n",
    "\n",
    "    while t < steps:\n",
    "        state = grid.int_as_state(state)\n",
    "        #print(state)\n",
    "        # Getting the next state\n",
    "        new_state, reward, done = grid.step(action, state)\n",
    "\n",
    "        # Choosing random next action with small chance\n",
    "        if t == int(0.2 * steps) or t == int(0.4 * steps) or t == int(0.6 * steps) or t == int(0.8 * steps):\n",
    "            new_action = r.randint(0,3)\n",
    "        \n",
    "        # Choose next action from Q-Value matrix\n",
    "        else:\n",
    "            new_action = np.argmax(q_values[new_state, :])\n",
    "\n",
    "        # Updating the Q-value matrix\n",
    "        update(state, new_state, reward, action, new_action)\n",
    "\n",
    "        state = new_state\n",
    "        action = new_action\n",
    "\n",
    "        # Updating the respective vaLues\n",
    "        t += 1\n",
    "\n",
    "        # Terminal state is reached\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "print(q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "step() missing 1 required positional argument: 'new_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12020/2968390856.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mnew_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: step() missing 1 required positional argument: 'new_state'"
     ]
    }
   ],
   "source": [
    "# Test Q-Values\n",
    "\n",
    "moves = 100\n",
    "\n",
    "for i in range(moves):\n",
    "    action = np.argmax(q_values[new_state, :])\n",
    "\n",
    "    new_state, reward, done = grid.step(action)\n",
    "    print(new_state)\n",
    "    print(reward)\n",
    "\n",
    "    if done:\n",
    "        print(\"finished\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f1073c099ddc7feaa79a7ad20594747d23b588351da1e73dea2959a263903ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('iannwtf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
